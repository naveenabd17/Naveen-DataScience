{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1:\n",
    "\n",
    "     Write a python program which searches all the product under a particular product from\n",
    "    www.amazon.in. The product to be searched will be taken as input from user. For e.g. If user\n",
    "    input is ‚Äòguitar‚Äô. Then search for guitars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.amazon.in/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search():\n",
    "    Search_tag=driver.find_element_by_id('twotabsearchtextbox')\n",
    "    search_input=str(input('Type here and I will get you there   '))\n",
    "    Search_tag.send_keys(search_input)\n",
    "    time.sleep(5)\n",
    "    search=driver.find_element_by_id('nav-search-submit-button')\n",
    "    search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type here and I will get you there   Guitar\n"
     ]
    }
   ],
   "source": [
    "search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2:\n",
    "    \n",
    "     In the above question, now scrape the following details of each product listed in first 3 pages\n",
    "    of your search results and save it in a dataframe and csv. In case if any product has less than 3\n",
    "    pages in search results then scrape all the products available under that product vertical.\n",
    "    Details to be scraped are: \"Brand Name\", \"Name of the Product\", \"Rating\", \"No. of Ratings\",\n",
    "    \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\", \"Other Details\" and\n",
    "    ‚ÄúProduct URL‚Äù. In case, if any of the details are missing for any of the product then replace it\n",
    "    by ‚Äú-‚Äú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand_name=[]\n",
    "for i in range(3):\n",
    "    try:\n",
    "        brand_tag=[]\n",
    "        brand_tag=driver.find_elements_by_xpath('//span[@class=\"a-size-base-plus a-color-base a-text-normal\"]')\n",
    "        for i in brand_tag:\n",
    "            Brand_name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Brand_name.append(None)\n",
    "    driver.find_element_by_xpath('//li[@class=\"a-last\"]/a').click()\n",
    "    time.sleep(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame()\n",
    "df2['Brand_name']=Brand_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ju√¢rez Acoustic Guitar, 38 Inch Cutaway, 038C ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kadence Acoustica Series Semi Acoustic Ash Woo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JUAREZ Arp√©ggio 41 Inch Acoustic Guitar Kit, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kadence Frontier Jumbo Semi Acoustic Guitar Wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ju√¢rez Acoustic Guitar, 38 Inch Cutaway, 038C ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Brand_name\n",
       "0  Ju√¢rez Acoustic Guitar, 38 Inch Cutaway, 038C ...\n",
       "1  Kadence Acoustica Series Semi Acoustic Ash Woo...\n",
       "2  JUAREZ Arp√©ggio 41 Inch Acoustic Guitar Kit, S...\n",
       "3  Kadence Frontier Jumbo Semi Acoustic Guitar Wi...\n",
       "4  Ju√¢rez Acoustic Guitar, 38 Inch Cutaway, 038C ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3:\n",
    "    \n",
    "    \n",
    "    Write a python program to access the search bar and search button on images.google.com and\n",
    "    scrape 100 images each for keywords ‚Äòfruits‚Äô, ‚Äòcars‚Äô and ‚ÄòMachine Learning‚Äô."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='images.google.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"8e0a4218bc3436e7b40cf5263642a825\", element=\"bbb1f7b9-30df-40dd-9372-43fd77373af2\")>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_tag=driver.find_element_by_xpath('//input[@class=\"gLFyf gsfi\"]')\n",
    "search_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"8e0a4218bc3436e7b40cf5263642a825\", element=\"3a351539-c9a1-47df-9534-11ae354e4164\")>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_button=driver.find_element_by_xpath('//button[@class=\"Tg7LZd\"]')\n",
    "search_button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tag.send_keys('fruits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching url\n",
    "image_url=[]\n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"bRMDJf islir\"]/img'):\n",
    "    image_url.append(i.get_attribute(\"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url_final=[]\n",
    "image_url_final=image_url[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"8e0a4218bc3436e7b40cf5263642a825\", element=\"eef3070f-55d6-42c3-9a63-3f8dfd5d2226\")>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_tag=driver.find_element_by_xpath('//input[@class=\"gLFyf gsfi\"]')\n",
    "search_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tag.send_keys('cars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element_by_xpath('//button[@class=\"Tg7LZd\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching url of car\n",
    "image_car=[]\n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"bRMDJf islir\"]/img'):\n",
    "    image_car.append(i.get_attribute(\"src\"))\n",
    "image_car_final=[]\n",
    "image_car_final=image_car[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tag=driver.find_element_by_xpath('//input[@class=\"gLFyf gsfi\"]')\n",
    "search_tag.send_keys('machine learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element_by_xpath('//button[@class=\"Tg7LZd\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching the image urls of the machine learning\n",
    "image_ml=[]\n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"bRMDJf islir\"]/img'):\n",
    "    image_ml.append(i.get_attribute(\"src\"))\n",
    "image_ml_final=[]\n",
    "image_ml_final=image_ml[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4:\n",
    "    \n",
    "    Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on\n",
    "    www.flipkart.com and scrape following details for all the search results displayed on 1st page.\n",
    "    Details to be scraped: ‚ÄúBrand Name‚Äù, ‚ÄúSmartphone name‚Äù, ‚ÄúColour‚Äù, ‚ÄúRAM‚Äù,\n",
    "    ‚ÄúStorage(ROM)‚Äù, ‚ÄúPrimary Camera‚Äù, ‚ÄúSecondary Camera‚Äù, ‚ÄúDisplay Size‚Äù, ‚ÄúDisplay\n",
    "    Resolution‚Äù, ‚ÄúProcessor‚Äù, ‚ÄúProcessor Cores‚Äù, ‚ÄúBattery Capacity‚Äù, ‚ÄúPrice‚Äù, ‚ÄúProduct URL‚Äù. In\n",
    "    case if any of the details is missing then replace it by ‚Äú- ‚Äú. Save your results in a dataframe\n",
    "    and CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"6c2ff2296e427f93840b869c0b5ae7c1\", element=\"1db6bb28-8eb1-4f69-b429-7157e23a5638\")>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_tag=driver.find_element_by_xpath('//div[@class=\"_3OO5Xc\"]/input')\n",
    "search_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tag.send_keys('Mi smartphones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "smartphone_tags=driver.find_elements_by_xpath('//div[@class=\"_4rR01T\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(smartphone_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching the urls\n",
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath('//a[@class=\"_1fQZEK\"]'):\n",
    "    urls.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand_tag=driver.find_elements_by_xpath('//div[@class=\"_4rR01T\"]')\n",
    "Brand_name=[]\n",
    "for i in Brand_tag:\n",
    "    Brand_name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=[]\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        \n",
    "\n",
    "        brand = driver.find_element_by_xpath('//a[@id=\"bylineInfo\"]')      \n",
    "\n",
    "        Brand.append(brand.text)\n",
    "\n",
    "    except NoSuchElementException:\n",
    "\n",
    "        Brand.append('-')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5:\n",
    "    \n",
    "    Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on\n",
    "    google maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.latlong.net/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"5cc5766a1a21c4c6c36574748f4d84f1\", element=\"63f7d440-369e-488e-82cc-4ec10ab2e2b9\")>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place=driver.find_element_by_id('place')\n",
    "place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"5cc5766a1a21c4c6c36574748f4d84f1\", element=\"32146eec-ab67-4d39-8e84-9c03260d3891\")>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find=driver.find_element_by_id('btnfind')\n",
    "find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat=[]\n",
    "long=[]\n",
    "def lat(x):\n",
    "    place.send_keys(x)\n",
    "    find.click()\n",
    "    for i in driver.find_element_by_id('lat'):\n",
    "        lat.append(i.text)\n",
    "    for i in driver.find_element_by_id('lng'):\n",
    "        long.append(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 6:\n",
    "    \n",
    "    Write a program to scrap details of all the funding deals for second quarter (i.e. July 20 ‚Äì\n",
    "    September 20) from trak.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://trak.in/india-startup-funding-investment-2015/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "date=[]\n",
    "for i in driver.find_elements_by_xpath('//td[@class=\"column-2\"]'):\n",
    "    date.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6=pd.DataFrame()\n",
    "df6['Date']=date[55:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "company=[]\n",
    "for i in driver.find_elements_by_xpath('//td[@class=\"column-3\"]'):\n",
    "    company.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6['company']=company[55:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Industry=[]\n",
    "for i in driver.find_elements_by_xpath('//td[@class=\"column-4\"]'):\n",
    "    Industry.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6['Industry']=Industry[55:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "city=[]\n",
    "for i in driver.find_elements_by_xpath('//td[@class=\"column-6\"]'):\n",
    "    city.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6['city']=city[55:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Investors_name=[]\n",
    "for i in driver.find_elements_by_xpath('//td[@class=\"column-7\"]'):\n",
    "    Investors_name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6['Investors_name']=Investors_name[55:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Investment_type=[]\n",
    "for i in driver.find_elements_by_xpath('//td[@class=\"column-8\"]'):\n",
    "    Investment_type.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6['Investment_type']=Investment_type[55:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount=[]\n",
    "for i in driver.find_elements_by_xpath('//td[@class=\"column-9\"]'):\n",
    "    amount.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6['amount']=amount[55:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>company</th>\n",
       "      <th>Industry</th>\n",
       "      <th>city</th>\n",
       "      <th>Investors_name</th>\n",
       "      <th>Investment_type</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08/09/2020</td>\n",
       "      <td>Byju‚Äôs</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Silver Lake, Tiger Global, General Atlantic an...</td>\n",
       "      <td>Private Equity</td>\n",
       "      <td>500,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/09/2020</td>\n",
       "      <td>mCaffeine</td>\n",
       "      <td>Personal Care</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Amicus Capital Private Equity I LLP, Amicus Ca...</td>\n",
       "      <td>Series B</td>\n",
       "      <td>3,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09/09/2020</td>\n",
       "      <td>Qshala</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Rainmatter Capital</td>\n",
       "      <td>Angel</td>\n",
       "      <td>370,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02/09/2020</td>\n",
       "      <td>Winzo</td>\n",
       "      <td>Online Gaming</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Kalaari Capital Partners, IndigoEdge Managemen...</td>\n",
       "      <td>Series B</td>\n",
       "      <td>15,500,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09/09/2020</td>\n",
       "      <td>Hippo Video</td>\n",
       "      <td>Video Customer Experience(CX) Platform</td>\n",
       "      <td>Newark, Delaware, United States of Amercia</td>\n",
       "      <td>Alpha Wave Incubation, Exfinity Venture Partne...</td>\n",
       "      <td>Series A</td>\n",
       "      <td>4,500,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      company                                Industry  \\\n",
       "0  08/09/2020       Byju‚Äôs                                 EduTech   \n",
       "1  12/09/2020    mCaffeine                           Personal Care   \n",
       "2  09/09/2020       Qshala                                 EduTech   \n",
       "3  02/09/2020        Winzo                           Online Gaming   \n",
       "4  09/09/2020  Hippo Video  Video Customer Experience(CX) Platform   \n",
       "\n",
       "                                         city  \\\n",
       "0                                   Bangalore   \n",
       "1                                      Mumbai   \n",
       "2                                   Bangalore   \n",
       "3                                   New Delhi   \n",
       "4  Newark, Delaware, United States of Amercia   \n",
       "\n",
       "                                      Investors_name Investment_type  \\\n",
       "0  Silver Lake, Tiger Global, General Atlantic an...  Private Equity   \n",
       "1  Amicus Capital Private Equity I LLP, Amicus Ca...        Series B   \n",
       "2                                 Rainmatter Capital           Angel   \n",
       "3  Kalaari Capital Partners, IndigoEdge Managemen...        Series B   \n",
       "4  Alpha Wave Incubation, Exfinity Venture Partne...        Series A   \n",
       "\n",
       "        amount  \n",
       "0  500,000,000  \n",
       "1    3,000,000  \n",
       "2      370,000  \n",
       "3   15,500,000  \n",
       "4    4,500,000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 7:\n",
    "    \n",
    "    Write a program to scrap all the available details of best gaming laptops from digit.in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.digit.in/search/?keyword=Best%20gaming%20laptops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asus G750JX-CV069P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo G50-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS G53J - A 3D gamer's delight but we want more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dell Vostro 15 3500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samsung Series 9 (NP-900X3C)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Brand Name\n",
       "0                                 Asus G750JX-CV069P\n",
       "1                                      Lenovo G50-30\n",
       "2  ASUS G53J - A 3D gamer's delight but we want more\n",
       "3                                Dell Vostro 15 3500\n",
       "4                       Samsung Series 9 (NP-900X3C)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Company_Name=[]\n",
    "for i in range(10):\n",
    "    for a in driver.find_elements_by_xpath('//div[@class=\"searchProduct-desc\"]'):\n",
    "        Company_Name.append(a.text)\n",
    "\n",
    "    driver.find_element_by_xpath('//a[@class=\"page-link\"]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "df7=pd.DataFrame()\n",
    "df7['Brand Name']=Company_Name\n",
    "\n",
    "df7.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 8:\n",
    "    \n",
    "    Write a python program to scrape the details for all billionaires from www.forbes.com.\n",
    "    Details to be scrapped: ‚ÄúRank‚Äù, ‚ÄúName‚Äù, ‚ÄúNet worth‚Äù, ‚ÄúAge‚Äù, ‚ÄúCitizenship‚Äù, ‚ÄúSource‚Äù,\n",
    "    ‚ÄúIndustry‚Äù."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.forbes.com/billionaires/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"rank\"]'):\n",
    "    Rank.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"personName\"]'):\n",
    "    Name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net_worth=[]\n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"netWorth\"]'):\n",
    "    Net_worth.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "age=[]\n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"age\"]'):\n",
    "    age.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Citizenship=[]\n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"countryOfCitizenship\"]'):\n",
    "    Citizenship.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Source=[]\n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"source\"]'):\n",
    "    Source.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Industry=[]\n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"source\"]/div/div'):\n",
    "    Industry.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Net_worth</th>\n",
       "      <th>Age</th>\n",
       "      <th>Citizenship</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Jeff Bezos</td>\n",
       "      <td>$177 B</td>\n",
       "      <td></td>\n",
       "      <td>United States</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>$151 B</td>\n",
       "      <td></td>\n",
       "      <td>United States</td>\n",
       "      <td>Tesla, SpaceX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Bernard Arnault &amp; family</td>\n",
       "      <td>$150 B</td>\n",
       "      <td></td>\n",
       "      <td>France</td>\n",
       "      <td>LVMH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Bill Gates</td>\n",
       "      <td>$124 B</td>\n",
       "      <td></td>\n",
       "      <td>United States</td>\n",
       "      <td>Microsoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>$97 B</td>\n",
       "      <td></td>\n",
       "      <td>United States</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank                      Name Net_worth Age    Citizenship         Source\n",
       "0   1.                Jeff Bezos    $177 B      United States         Amazon\n",
       "1   2.                 Elon Musk    $151 B      United States  Tesla, SpaceX\n",
       "2   3.  Bernard Arnault & family    $150 B             France           LVMH\n",
       "3   4.                Bill Gates    $124 B      United States      Microsoft\n",
       "4   5.           Mark Zuckerberg     $97 B      United States       Facebook"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8=pd.DataFrame()\n",
    "df8['Rank']=Rank\n",
    "df8['Name']=Name\n",
    "df8['Net_worth']=Net_worth\n",
    "df8['Age']=age\n",
    "df8['Citizenship']=Citizenship\n",
    "df8['Source']=Source\n",
    "df8.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 9:\n",
    "    \n",
    "    Write a program to extract at least 500 Comments, Comment upvote and time when comment\n",
    "    was posted from any YouTube Video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.youtube.com/watch?v=qsKoT__cmAw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_tag=driver.find_elements_by_id('content-text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment=[]\n",
    "for i in comments_tag:\n",
    "    comment.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The 1.4k people who disliked are just annoyed because they didn't follow the instructions correctly\",\n",
       " 'Imagine I have been unable to open the door for almost 24 years, and now I learned from this man.',\n",
       " 'Help I now cannot close my door. Part two please.',\n",
       " 'I am still looking for a tutorial How to open eyes üòÇüòÇ',\n",
       " 'Disclaimer: the above action is dangerous, do it under adult supervision!',\n",
       " 'Quarantine: Day 47 ‚Äújust checking if i can open the door ‚Äú',\n",
       " '6.5k people demanding for another tutorial on how to close the door. Their doors are still open up to this day',\n",
       " 'Finally I can go outside my room! Thanx!!',\n",
       " \"I've learned a lot today, Thank you this video is really useful.\",\n",
       " 'I have decided to donate my two eyes and ears after watching this emotional and inspiring video . Now I can leave this planet very happily and peacefully. Thank you so much for uploading such an inspiring and heart wrenching video.\\nHuge respect to you üôèüôè',\n",
       " 'Finally!! I‚Äôve been stuck in my room ever since the ‚Äúhow to close a door‚Äù episode',\n",
       " 'Why would people disliked thus vid ??? this is what they searched forü§ß',\n",
       " 'Super useful, I‚Äôve been locked in the basement for 9 years and I‚Äôve watched this video so many time and I finally figured it out! Thanks!',\n",
       " \"Okay now i realized millions of people doesn't know how to open a door üòÇ\",\n",
       " 'Omg finally someone that made a video on how to open a door!! I‚Äôve been stuck in my room forever. Thank you for showing me, I always wondered what that weird thing was on my door',\n",
       " 'UwU',\n",
       " 'so informative my door opened within a second i was struggling so much thank u üòΩ',\n",
       " \"Omg thank God I don't have to break the door every time I want to go out thank you\",\n",
       " 'Hey ! can you make a tutorial for closing it cause it was opened for 14 years',\n",
       " 'After seeing how this series ends, this video feels like a breathe of fresh air.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 10:\n",
    "    \n",
    "    10. Write a python program to scrape a data for all available Hostels from\n",
    "    https://www.hostelworld.com/ in ‚ÄúLondon‚Äù location. You have to scrape hostel name,\n",
    "    distance from city centre, ratings, total reviews, overall reviews, privates from price, dorms\n",
    "    from price, facilities and property description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.hostelworld.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tag=driver.find_element_by_id('location-text-input-field')\n",
    "search_tag.send_keys('London')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element_by_xpath('//span[@class=\"search-icon icon\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_tag=driver.find_element_by_xpath('//div[@class=\"pagination-item pagination-next\"]')\n",
    "next_tag.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostel_name_tag=driver.find_elements_by_xpath('//h2[@class=\"title title-6\"]')\n",
    "hostel_name=[]\n",
    "try:\n",
    "    \n",
    "    for i in hostel_name_tag:\n",
    "        hostel_name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    hostel_name.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_tag=driver.find_elements_by_xpath('//span[@class=\"description\"]')\n",
    "distance=[]\n",
    "try:\n",
    "    \n",
    "    for i in distance_tag:\n",
    "        distance.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    distance.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_tag=driver.find_elements_by_xpath('//div[@class=\"score orange big\"]')\n",
    "ratings=[]\n",
    "try:\n",
    "    \n",
    "    for i in rating_tag:\n",
    "        ratings.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    ratings.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_tag=driver.find_elements_by_xpath('//div[@class=\"reviews\"]')\n",
    "review=[]\n",
    "try:\n",
    "    \n",
    "    for i in review_tag:\n",
    "        review.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    review.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_review_tag=driver.find_elements_by_xpath('//div[@class=\"keyword\"]/span')\n",
    "overall_review=[]\n",
    "try:\n",
    "    \n",
    "    for i in review_tag:\n",
    "        overall_review.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    overall_review.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(overall_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "privates_from_tag=driver.find_elements_by_xpath('//div[@class=\"price title-5\"]')\n",
    "privates_from=[]\n",
    "try:\n",
    "    \n",
    "    for i in privates_from_tag:\n",
    "        privates_from.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    privates_from.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(privates_from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10=pd.DataFrame()\n",
    "df10['Hostel_name']=hostel_name\n",
    "df10['distance from citycentre']=distance\n",
    "df10['ratings']=ratings\n",
    "df10['review']=review\n",
    "df10['overall_review']=overall_review\n",
    "df10['privates_from']=privates_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
