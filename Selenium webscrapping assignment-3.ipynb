{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1:\n",
    "\n",
    "     Write a python program which searches all the product under a particular product from\n",
    "    www.amazon.in. The product to be searched will be taken as input from user. For e.g. If user\n",
    "    input is ‘guitar’. Then search for guitars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.amazon.in/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search():\n",
    "    Search_tag=driver.find_element_by_id('twotabsearchtextbox')\n",
    "    search_input=str(input('Type here and I will get you there   '))\n",
    "    Search_tag.send_keys(search_input)\n",
    "    time.sleep(5)\n",
    "    search=driver.find_element_by_id('nav-search-submit-button')\n",
    "    search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type here and I will get you there   Guitar\n"
     ]
    }
   ],
   "source": [
    "search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2:\n",
    "    \n",
    "     In the above question, now scrape the following details of each product listed in first 3 pages\n",
    "    of your search results and save it in a dataframe and csv. In case if any product has less than 3\n",
    "    pages in search results then scrape all the products available under that product vertical.\n",
    "    Details to be scraped are: \"Brand Name\", \"Name of the Product\", \"Rating\", \"No. of Ratings\",\n",
    "    \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\", \"Other Details\" and\n",
    "    “Product URL”. In case, if any of the details are missing for any of the product then replace it\n",
    "    by “-“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand_name=[]\n",
    "for i in range(3):\n",
    "    try:\n",
    "        brand_tag=[]\n",
    "        brand_tag=driver.find_elements_by_xpath('//span[@class=\"a-size-base-plus a-color-base a-text-normal\"]')\n",
    "        for i in brand_tag:\n",
    "            Brand_name.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Brand_name.append(None)\n",
    "    driver.find_element_by_xpath('//li[@class=\"a-last\"]/a').click()\n",
    "    time.sleep(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame()\n",
    "df2['Brand_name']=Brand_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Juârez Acoustic Guitar, 38 Inch Cutaway, 038C ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kadence Acoustica Series Semi Acoustic Ash Woo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JUAREZ Arpéggio 41 Inch Acoustic Guitar Kit, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kadence Frontier Jumbo Semi Acoustic Guitar Wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Juârez Acoustic Guitar, 38 Inch Cutaway, 038C ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Brand_name\n",
       "0  Juârez Acoustic Guitar, 38 Inch Cutaway, 038C ...\n",
       "1  Kadence Acoustica Series Semi Acoustic Ash Woo...\n",
       "2  JUAREZ Arpéggio 41 Inch Acoustic Guitar Kit, S...\n",
       "3  Kadence Frontier Jumbo Semi Acoustic Guitar Wi...\n",
       "4  Juârez Acoustic Guitar, 38 Inch Cutaway, 038C ..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3:\n",
    "    \n",
    "    \n",
    "    Write a python program to access the search bar and search button on images.google.com and\n",
    "    scrape 100 images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='images.google.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"8e0a4218bc3436e7b40cf5263642a825\", element=\"bbb1f7b9-30df-40dd-9372-43fd77373af2\")>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_tag=driver.find_element_by_xpath('//input[@class=\"gLFyf gsfi\"]')\n",
    "search_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"8e0a4218bc3436e7b40cf5263642a825\", element=\"3a351539-c9a1-47df-9534-11ae354e4164\")>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_button=driver.find_element_by_xpath('//button[@class=\"Tg7LZd\"]')\n",
    "search_button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tag.send_keys('fruits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching url\n",
    "image_url=[]\n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"bRMDJf islir\"]/img'):\n",
    "    image_url.append(i.get_attribute(\"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url_final=[]\n",
    "image_url_final=image_url[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"8e0a4218bc3436e7b40cf5263642a825\", element=\"eef3070f-55d6-42c3-9a63-3f8dfd5d2226\")>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_tag=driver.find_element_by_xpath('//input[@class=\"gLFyf gsfi\"]')\n",
    "search_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tag.send_keys('cars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element_by_xpath('//button[@class=\"Tg7LZd\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching url of car\n",
    "image_car=[]\n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"bRMDJf islir\"]/img'):\n",
    "    image_car.append(i.get_attribute(\"src\"))\n",
    "image_car_final=[]\n",
    "image_car_final=image_car[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tag=driver.find_element_by_xpath('//input[@class=\"gLFyf gsfi\"]')\n",
    "search_tag.send_keys('machine learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element_by_xpath('//button[@class=\"Tg7LZd\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching the image urls of the machine learning\n",
    "image_ml=[]\n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"bRMDJf islir\"]/img'):\n",
    "    image_ml.append(i.get_attribute(\"src\"))\n",
    "image_ml_final=[]\n",
    "image_ml_final=image_ml[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4:\n",
    "    \n",
    "    Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on\n",
    "    www.flipkart.com and scrape following details for all the search results displayed on 1st page.\n",
    "    Details to be scraped: “Brand Name”, “Smartphone name”, “Colour”, “RAM”,\n",
    "    “Storage(ROM)”, “Primary Camera”, “Secondary Camera”, “Display Size”, “Display\n",
    "    Resolution”, “Processor”, “Processor Cores”, “Battery Capacity”, “Price”, “Product URL”. In\n",
    "    case if any of the details is missing then replace it by “- “. Save your results in a dataframe\n",
    "    and CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"6c2ff2296e427f93840b869c0b5ae7c1\", element=\"1db6bb28-8eb1-4f69-b429-7157e23a5638\")>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_tag=driver.find_element_by_xpath('//div[@class=\"_3OO5Xc\"]/input')\n",
    "search_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tag.send_keys('Mi smartphones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "smartphone_tags=driver.find_elements_by_xpath('//div[@class=\"_4rR01T\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(smartphone_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetching the urls\n",
    "urls=[]\n",
    "for i in driver.find_elements_by_xpath('//a[@class=\"_1fQZEK\"]'):\n",
    "    urls.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand_tag=driver.find_elements_by_xpath('//div[@class=\"_4rR01T\"]')\n",
    "Brand_name=[]\n",
    "for i in Brand_tag:\n",
    "    Brand_name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=[]\n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        \n",
    "\n",
    "        brand = driver.find_element_by_xpath('//a[@id=\"bylineInfo\"]')      \n",
    "\n",
    "        Brand.append(brand.text)\n",
    "\n",
    "    except NoSuchElementException:\n",
    "\n",
    "        Brand.append('-')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5:\n",
    "    \n",
    "    Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on\n",
    "    google maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.latlong.net/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"5cc5766a1a21c4c6c36574748f4d84f1\", element=\"63f7d440-369e-488e-82cc-4ec10ab2e2b9\")>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place=driver.find_element_by_id('place')\n",
    "place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"5cc5766a1a21c4c6c36574748f4d84f1\", element=\"32146eec-ab67-4d39-8e84-9c03260d3891\")>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find=driver.find_element_by_id('btnfind')\n",
    "find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat=[]\n",
    "long=[]\n",
    "def lat(x):\n",
    "    place.send_keys(x)\n",
    "    find.click()\n",
    "    for i in driver.find_element_by_id('lat'):\n",
    "        lat.append(i.text)\n",
    "    for i in driver.find_element_by_id('lng'):\n",
    "        long.append(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 6:\n",
    "    \n",
    "    Write a program to scrap details of all the funding deals for second quarter (i.e. July 20 –\n",
    "    September 20) from trak.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://trak.in/india-startup-funding-investment-2015/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "date=[]\n",
    "for i in driver.find_elements_by_xpath('//td[@class=\"column-2\"]'):\n",
    "    date.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6=pd.DataFrame()\n",
    "df6['Date']=date[55:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "company=[]\n",
    "for i in driver.find_elements_by_xpath('//td[@class=\"column-3\"]'):\n",
    "    company.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6['company']=company[55:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Industry=[]\n",
    "for i in driver.find_elements_by_xpath('//td[@class=\"column-4\"]'):\n",
    "    Industry.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6['Industry']=Industry[55:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "city=[]\n",
    "for i in driver.find_elements_by_xpath('//td[@class=\"column-6\"]'):\n",
    "    city.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6['city']=city[55:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Investors_name=[]\n",
    "for i in driver.find_elements_by_xpath('//td[@class=\"column-7\"]'):\n",
    "    Investors_name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6['Investors_name']=Investors_name[55:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Investment_type=[]\n",
    "for i in driver.find_elements_by_xpath('//td[@class=\"column-8\"]'):\n",
    "    Investment_type.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6['Investment_type']=Investment_type[55:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount=[]\n",
    "for i in driver.find_elements_by_xpath('//td[@class=\"column-9\"]'):\n",
    "    amount.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6['amount']=amount[55:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>company</th>\n",
       "      <th>Industry</th>\n",
       "      <th>city</th>\n",
       "      <th>Investors_name</th>\n",
       "      <th>Investment_type</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08/09/2020</td>\n",
       "      <td>Byju’s</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Silver Lake, Tiger Global, General Atlantic an...</td>\n",
       "      <td>Private Equity</td>\n",
       "      <td>500,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/09/2020</td>\n",
       "      <td>mCaffeine</td>\n",
       "      <td>Personal Care</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Amicus Capital Private Equity I LLP, Amicus Ca...</td>\n",
       "      <td>Series B</td>\n",
       "      <td>3,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09/09/2020</td>\n",
       "      <td>Qshala</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Rainmatter Capital</td>\n",
       "      <td>Angel</td>\n",
       "      <td>370,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02/09/2020</td>\n",
       "      <td>Winzo</td>\n",
       "      <td>Online Gaming</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Kalaari Capital Partners, IndigoEdge Managemen...</td>\n",
       "      <td>Series B</td>\n",
       "      <td>15,500,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09/09/2020</td>\n",
       "      <td>Hippo Video</td>\n",
       "      <td>Video Customer Experience(CX) Platform</td>\n",
       "      <td>Newark, Delaware, United States of Amercia</td>\n",
       "      <td>Alpha Wave Incubation, Exfinity Venture Partne...</td>\n",
       "      <td>Series A</td>\n",
       "      <td>4,500,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      company                                Industry  \\\n",
       "0  08/09/2020       Byju’s                                 EduTech   \n",
       "1  12/09/2020    mCaffeine                           Personal Care   \n",
       "2  09/09/2020       Qshala                                 EduTech   \n",
       "3  02/09/2020        Winzo                           Online Gaming   \n",
       "4  09/09/2020  Hippo Video  Video Customer Experience(CX) Platform   \n",
       "\n",
       "                                         city  \\\n",
       "0                                   Bangalore   \n",
       "1                                      Mumbai   \n",
       "2                                   Bangalore   \n",
       "3                                   New Delhi   \n",
       "4  Newark, Delaware, United States of Amercia   \n",
       "\n",
       "                                      Investors_name Investment_type  \\\n",
       "0  Silver Lake, Tiger Global, General Atlantic an...  Private Equity   \n",
       "1  Amicus Capital Private Equity I LLP, Amicus Ca...        Series B   \n",
       "2                                 Rainmatter Capital           Angel   \n",
       "3  Kalaari Capital Partners, IndigoEdge Managemen...        Series B   \n",
       "4  Alpha Wave Incubation, Exfinity Venture Partne...        Series A   \n",
       "\n",
       "        amount  \n",
       "0  500,000,000  \n",
       "1    3,000,000  \n",
       "2      370,000  \n",
       "3   15,500,000  \n",
       "4    4,500,000  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 7:\n",
    "    \n",
    "    Write a program to scrap all the available details of best gaming laptops from digit.in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.digit.in/search/?keyword=Best%20gaming%20laptops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Asus G750JX-CV069P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo G50-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS G53J - A 3D gamer's delight but we want more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dell Vostro 15 3500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samsung Series 9 (NP-900X3C)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Brand Name\n",
       "0                                 Asus G750JX-CV069P\n",
       "1                                      Lenovo G50-30\n",
       "2  ASUS G53J - A 3D gamer's delight but we want more\n",
       "3                                Dell Vostro 15 3500\n",
       "4                       Samsung Series 9 (NP-900X3C)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Company_Name=[]\n",
    "for i in range(10):\n",
    "    for a in driver.find_elements_by_xpath('//div[@class=\"searchProduct-desc\"]'):\n",
    "        Company_Name.append(a.text)\n",
    "\n",
    "    driver.find_element_by_xpath('//a[@class=\"page-link\"]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "df7=pd.DataFrame()\n",
    "df7['Brand Name']=Company_Name\n",
    "\n",
    "df7.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 8:\n",
    "    \n",
    "    Write a python program to scrape the details for all billionaires from www.forbes.com.\n",
    "    Details to be scrapped: “Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”,\n",
    "    “Industry”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.forbes.com/billionaires/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"rank\"]'):\n",
    "    Rank.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"personName\"]'):\n",
    "    Name.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net_worth=[]\n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"netWorth\"]'):\n",
    "    Net_worth.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "age=[]\n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"age\"]'):\n",
    "    age.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Citizenship=[]\n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"countryOfCitizenship\"]'):\n",
    "    Citizenship.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Source=[]\n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"source\"]'):\n",
    "    Source.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "Industry=[]\n",
    "for i in driver.find_elements_by_xpath('//div[@class=\"source\"]/div/div'):\n",
    "    Industry.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Net_worth</th>\n",
       "      <th>Age</th>\n",
       "      <th>Citizenship</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Jeff Bezos</td>\n",
       "      <td>$177 B</td>\n",
       "      <td></td>\n",
       "      <td>United States</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>$151 B</td>\n",
       "      <td></td>\n",
       "      <td>United States</td>\n",
       "      <td>Tesla, SpaceX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Bernard Arnault &amp; family</td>\n",
       "      <td>$150 B</td>\n",
       "      <td></td>\n",
       "      <td>France</td>\n",
       "      <td>LVMH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Bill Gates</td>\n",
       "      <td>$124 B</td>\n",
       "      <td></td>\n",
       "      <td>United States</td>\n",
       "      <td>Microsoft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>$97 B</td>\n",
       "      <td></td>\n",
       "      <td>United States</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank                      Name Net_worth Age    Citizenship         Source\n",
       "0   1.                Jeff Bezos    $177 B      United States         Amazon\n",
       "1   2.                 Elon Musk    $151 B      United States  Tesla, SpaceX\n",
       "2   3.  Bernard Arnault & family    $150 B             France           LVMH\n",
       "3   4.                Bill Gates    $124 B      United States      Microsoft\n",
       "4   5.           Mark Zuckerberg     $97 B      United States       Facebook"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8=pd.DataFrame()\n",
    "df8['Rank']=Rank\n",
    "df8['Name']=Name\n",
    "df8['Net_worth']=Net_worth\n",
    "df8['Age']=age\n",
    "df8['Citizenship']=Citizenship\n",
    "df8['Source']=Source\n",
    "df8.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 9:\n",
    "    \n",
    "    Write a program to extract at least 500 Comments, Comment upvote and time when comment\n",
    "    was posted from any YouTube Video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.youtube.com/watch?v=qsKoT__cmAw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_tag=driver.find_elements_by_id('content-text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment=[]\n",
    "for i in comments_tag:\n",
    "    comment.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The 1.4k people who disliked are just annoyed because they didn't follow the instructions correctly\",\n",
       " 'Imagine I have been unable to open the door for almost 24 years, and now I learned from this man.',\n",
       " 'Help I now cannot close my door. Part two please.',\n",
       " 'I am still looking for a tutorial How to open eyes 😂😂',\n",
       " 'Disclaimer: the above action is dangerous, do it under adult supervision!',\n",
       " 'Quarantine: Day 47 “just checking if i can open the door “',\n",
       " '6.5k people demanding for another tutorial on how to close the door. Their doors are still open up to this day',\n",
       " 'Finally I can go outside my room! Thanx!!',\n",
       " \"I've learned a lot today, Thank you this video is really useful.\",\n",
       " 'I have decided to donate my two eyes and ears after watching this emotional and inspiring video . Now I can leave this planet very happily and peacefully. Thank you so much for uploading such an inspiring and heart wrenching video.\\nHuge respect to you 🙏🙏',\n",
       " 'Finally!! I’ve been stuck in my room ever since the “how to close a door” episode',\n",
       " 'Why would people disliked thus vid ??? this is what they searched for🤧',\n",
       " 'Super useful, I’ve been locked in the basement for 9 years and I’ve watched this video so many time and I finally figured it out! Thanks!',\n",
       " \"Okay now i realized millions of people doesn't know how to open a door 😂\",\n",
       " 'Omg finally someone that made a video on how to open a door!! I’ve been stuck in my room forever. Thank you for showing me, I always wondered what that weird thing was on my door',\n",
       " 'UwU',\n",
       " 'so informative my door opened within a second i was struggling so much thank u 😽',\n",
       " \"Omg thank God I don't have to break the door every time I want to go out thank you\",\n",
       " 'Hey ! can you make a tutorial for closing it cause it was opened for 14 years',\n",
       " 'After seeing how this series ends, this video feels like a breathe of fresh air.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 10:\n",
    "    \n",
    "    10. Write a python program to scrape a data for all available Hostels from\n",
    "    https://www.hostelworld.com/ in “London” location. You have to scrape hostel name,\n",
    "    distance from city centre, ratings, total reviews, overall reviews, privates from price, dorms\n",
    "    from price, facilities and property description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.hostelworld.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tag=driver.find_element_by_id('location-text-input-field')\n",
    "search_tag.send_keys('London')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element_by_xpath('//span[@class=\"search-icon icon\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_tag=driver.find_element_by_xpath('//div[@class=\"pagination-item pagination-next\"]')\n",
    "next_tag.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostel_name_tag=driver.find_elements_by_xpath('//h2[@class=\"title title-6\"]')\n",
    "hostel_name=[]\n",
    "try:\n",
    "    \n",
    "    for i in hostel_name_tag:\n",
    "        hostel_name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    hostel_name.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_tag=driver.find_elements_by_xpath('//span[@class=\"description\"]')\n",
    "distance=[]\n",
    "try:\n",
    "    \n",
    "    for i in distance_tag:\n",
    "        distance.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    distance.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_tag=driver.find_elements_by_xpath('//div[@class=\"score orange big\"]')\n",
    "ratings=[]\n",
    "try:\n",
    "    \n",
    "    for i in rating_tag:\n",
    "        ratings.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    ratings.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_tag=driver.find_elements_by_xpath('//div[@class=\"reviews\"]')\n",
    "review=[]\n",
    "try:\n",
    "    \n",
    "    for i in review_tag:\n",
    "        review.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    review.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_review_tag=driver.find_elements_by_xpath('//div[@class=\"keyword\"]/span')\n",
    "overall_review=[]\n",
    "try:\n",
    "    \n",
    "    for i in review_tag:\n",
    "        overall_review.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    overall_review.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(overall_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "privates_from_tag=driver.find_elements_by_xpath('//div[@class=\"price title-5\"]')\n",
    "privates_from=[]\n",
    "try:\n",
    "    \n",
    "    for i in privates_from_tag:\n",
    "        privates_from.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    privates_from.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(privates_from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10=pd.DataFrame()\n",
    "df10['Hostel_name']=hostel_name\n",
    "df10['distance from citycentre']=distance\n",
    "df10['ratings']=ratings\n",
    "df10['review']=review\n",
    "df10['overall_review']=overall_review\n",
    "df10['privates_from']=privates_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
